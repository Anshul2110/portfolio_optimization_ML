{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models, expected_returns, plotting\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10c99f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions sample:\n",
      "        Date  Pred_Prob_Up  True_Label\n",
      "0 2024-02-29      0.524484           0\n",
      "1 2024-02-29      0.525042           1\n",
      "2 2024-02-29      0.525421           1\n",
      "3 2024-02-29      0.525758           1\n",
      "4 2024-02-29      0.525758           0\n",
      "Returns sample:\n",
      "                AAPL      MSFT      AMZN      TSLA       JPM\n",
      "Date                                                        \n",
      "2018-01-03 -0.000174  0.004654  0.012775 -0.010233  0.001019\n",
      "2018-01-04  0.004645  0.008801  0.004476 -0.008290  0.014326\n",
      "2018-01-05  0.011385  0.012398  0.016163  0.006230 -0.006420\n",
      "2018-01-08 -0.003715  0.001020  0.014425  0.062638  0.001477\n",
      "2018-01-09 -0.000115 -0.000679  0.004676 -0.008085  0.005069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading predictions & historical returns\n",
    "\n",
    "preds = pd.read_csv(\"C:\\\\Users\\\\ansul\\\\OneDrive\\\\Desktop\\\\data science project\\\\portfolio_optimization_ML\\\\data\\\\processed\\\\predicted_probabilities.csv\", parse_dates=[\"Date\"])\n",
    "returns = pd.read_csv(\"C:\\\\Users\\\\ansul\\\\OneDrive\\\\Desktop\\\\data science project\\\\portfolio_optimization_ML\\\\data\\\\processed\\\\daily_returns.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "print(\"Predictions sample:\")\n",
    "print(preds.head())\n",
    "\n",
    "print(\"Returns sample:\")\n",
    "print(returns.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfed052f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ticker'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m preds[\u001b[33m\"\u001b[39m\u001b[33mExpected_Return\u001b[39m\u001b[33m\"\u001b[39m] = preds[\u001b[33m\"\u001b[39m\u001b[33mPred_Prob_Up\u001b[39m\u001b[33m\"\u001b[39m] * avg_daily_return\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Take last predicted return per ticker\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m mu_ml = \u001b[43mpreds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTicker\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mExpected_Return\u001b[39m\u001b[33m\"\u001b[39m].last()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPredicted Expected Returns (latest):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(mu_ml)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ansul\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:9190\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9196\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ansul\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ansul\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Ticker'"
     ]
    }
   ],
   "source": [
    "# Converting predicted probability â†’ expected return\n",
    "\n",
    "# Scale probability into expected daily return using historical avg return\n",
    "avg_daily_return = returns.mean().mean()\n",
    "preds[\"Expected_Return\"] = preds[\"Pred_Prob_Up\"] * avg_daily_return\n",
    "\n",
    "# Take last predicted return per ticker\n",
    "mu_ml = preds.groupby(\"Ticker\")[\"Expected_Return\"].last()\n",
    "\n",
    "print(\"\\nPredicted Expected Returns (latest):\")\n",
    "print(mu_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 3: Estimate covariance matrix (historical)\n",
    "# -----------------------------\n",
    "mu_hist = expected_returns.mean_historical_return(returns)  # classical expected returns\n",
    "S = risk_models.sample_cov(returns)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 4: Classical Portfolio (baseline)\n",
    "# -----------------------------\n",
    "ef_classical = EfficientFrontier(mu_hist, S)\n",
    "weights_classical = ef_classical.max_sharpe()\n",
    "cleaned_weights_classical = ef_classical.clean_weights()\n",
    "performance_classical = ef_classical.portfolio_performance(verbose=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 5: ML-driven Portfolio\n",
    "# -----------------------------\n",
    "ef_ml = EfficientFrontier(mu_ml, S)\n",
    "weights_ml = ef_ml.max_sharpe()\n",
    "cleaned_weights_ml = ef_ml.clean_weights()\n",
    "performance_ml = ef_ml.portfolio_performance(verbose=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 6: Compare Results\n",
    "# -----------------------------\n",
    "print(\"\\nðŸ”¹ Classical Portfolio Weights:\")\n",
    "print(cleaned_weights_classical)\n",
    "\n",
    "print(\"\\nðŸ”¹ ML-Driven Portfolio Weights:\")\n",
    "print(cleaned_weights_ml)\n",
    "\n",
    "print(\"\\nðŸ“Š Performance Comparison\")\n",
    "print(\"Classical:\", performance_classical)\n",
    "print(\"ML-Driven:\", performance_ml)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 7: Visualization - Allocation\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,6))\n",
    "\n",
    "# Pie chart: Classical Portfolio\n",
    "ax[0].pie(cleaned_weights_classical.values(),\n",
    "          labels=cleaned_weights_classical.keys(),\n",
    "          autopct='%1.1f%%', startangle=90)\n",
    "ax[0].set_title(\"Classical Portfolio Allocation\")\n",
    "\n",
    "# Pie chart: ML-Driven Portfolio\n",
    "ax[1].pie(cleaned_weights_ml.values(),\n",
    "          labels=cleaned_weights_ml.keys(),\n",
    "          autopct='%1.1f%%', startangle=90)\n",
    "ax[1].set_title(\"ML-Driven Portfolio Allocation\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 8: Efficient Frontier Plot\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(10,7))\n",
    "plotting.plot_efficient_frontier(ef_classical, show_assets=True)\n",
    "\n",
    "# Mark classical max Sharpe\n",
    "ret_c, vol_c, sharpe_c = performance_classical\n",
    "plt.scatter(vol_c, ret_c, marker=\"*\", color=\"red\", s=200, label=\"Classical Max Sharpe\")\n",
    "\n",
    "# Mark ML max Sharpe\n",
    "ret_ml, vol_ml, sharpe_ml = performance_ml\n",
    "plt.scatter(vol_ml, ret_ml, marker=\"*\", color=\"blue\", s=200, label=\"ML Max Sharpe\")\n",
    "\n",
    "plt.title(\"Efficient Frontier: Classical vs ML-Driven Portfolio\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“Œ Step 9: Portfolio Backtest (Cumulative Returns)\n",
    "# -----------------------------\n",
    "# Compute daily portfolio returns for both strategies\n",
    "w_classical = pd.Series(cleaned_weights_classical)\n",
    "w_ml = pd.Series(cleaned_weights_ml)\n",
    "\n",
    "port_ret_classical = (returns * w_classical).sum(axis=1)\n",
    "port_ret_ml = (returns * w_ml).sum(axis=1)\n",
    "\n",
    "cum_ret_classical = (1 + port_ret_classical).cumprod()\n",
    "cum_ret_ml = (1 + port_ret_ml).cumprod()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cum_ret_classical, label=\"Classical Portfolio\")\n",
    "plt.plot(cum_ret_ml, label=\"ML-Driven Portfolio\")\n",
    "plt.title(\"Cumulative Returns Comparison\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Growth\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
